{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspiration for Neural Net: https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f575571edf0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pitcher\n",
    "from random import shuffle\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "player = 'verlander'\n",
    "data = pd.read_csv('Data/raw_data/'+player+'.csv')\n",
    "data = pitcher.clean_data(data)\n",
    "ABs = pitcher.get_abs(data)\n",
    "reps = pitcher.get_reps(ABs)\n",
    "reps = pitcher.drop_nas(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get train, validate, and test sets (60-20-20)\n",
    "shuffle(reps)\n",
    "cutoff1 = int(len(reps)*0.6)\n",
    "cutoff2 = cutoff1 + int(len(reps)*.2)\n",
    "train = reps[1:cutoff1]\n",
    "validate = reps[cutoff1:cutoff2]\n",
    "test = reps[cutoff2:]\n",
    "\n",
    "\n",
    "#get train, validate, and test batches\n",
    "batch_size = 50\n",
    "train_batches = pitcher.get_batches(train,batch_size)\n",
    "test_batches = pitcher.get_batches(test,batch_size)\n",
    "validate_batches = pitcher.get_batches(validate,batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(batches,model):\n",
    "    length = len(batches)*len(batches[0][0])\n",
    "    num_right = 0\n",
    "    ch_count = 0\n",
    "    predict_ch = 0\n",
    "    cu_count = 0\n",
    "    predict_cu = 0\n",
    "    sl_count = 0\n",
    "    predict_sl = 0\n",
    "    ff_count = 0\n",
    "    predict_ff = 0\n",
    "    ff_right = 0\n",
    "    ch_right = 0\n",
    "    sl_right = 0\n",
    "    cu_right = 0\n",
    "    for batch in batches:\n",
    "        with torch.no_grad():\n",
    "            prev_pitches,pre_pitch, ptypes = batch\n",
    "            prevs_in = torch.tensor(prev_pitches, dtype=torch.float)\n",
    "            rep_in = torch.tensor(pre_pitch, dtype=torch.float)\n",
    "            #targets = tag_to_ix[ptypes]\n",
    "            if len(ptypes) > 1:\n",
    "                targets = [tag_to_ix[ptype] for ptype in ptypes]\n",
    "            else:\n",
    "                targets = tag_to_ix[ptypes[0]]\n",
    "            tag_scores = model((prevs_in,rep_in))\n",
    "            #print(tag_scores)\n",
    "            preds = [tag_score.max(0) for tag_score in tag_scores]\n",
    "            #print(index.item())\n",
    "            if len(ptypes) > 1:\n",
    "                for pred,target in zip(preds,targets):\n",
    "                    _,index = pred\n",
    "                    if target == 1:\n",
    "                        ff_count += 1\n",
    "                    if index.item() == 1:\n",
    "                        predict_ff += 1\n",
    "                    if target == 1 and index.item() == 1:\n",
    "                        ff_right += 1\n",
    "                    if target == 0:\n",
    "                        cu_count += 1\n",
    "                    if index.item() == 0:\n",
    "                        predict_cu += 1\n",
    "                    if target == 0 and index.item() == 0:\n",
    "                        cu_right += 1\n",
    "                    if index.item() == target:\n",
    "                        num_right += 1\n",
    "            else:\n",
    "                _,index = preds[0]\n",
    "                if targets == 1:\n",
    "                    ff_count += 1\n",
    "                if index.item() == 1:\n",
    "                    predict_ff += 1\n",
    "                if targets == 1 and index.item() == 1:\n",
    "                    ff_right += 1\n",
    "                if targets == 0:\n",
    "                    cu_count += 1\n",
    "                if index.item() == 0:\n",
    "                    predict_cu += 1\n",
    "                if targets == 0 and index.item() == 0:\n",
    "                    cu_right += 1\n",
    "                if index.item() == targets:\n",
    "                    num_right += 1\n",
    "    ff_rate = ff_count/length\n",
    "    pred_ff_rate = predict_ff/length\n",
    "    ff_acc = ff_right/ff_count\n",
    "    cu_rate = cu_count/length\n",
    "    pred_cu_rate = predict_cu/length\n",
    "    cu_acc = cu_right/cu_count\n",
    "    accuracy = num_right/length\n",
    "    print(\"______________________________________\")\n",
    "    print(\"Non-Fastball rate:\",cu_rate)\n",
    "    print(\"Predicted Non-Fastball rate:\",pred_cu_rate)\n",
    "    print(\"Non-Fastball accuracy:\",cu_acc)\n",
    "    print(\"______________________________________\")\n",
    "    print(\"Fastball rate:\",ff_rate)\n",
    "    print(\"Predicted Fastball rate:\",pred_ff_rate)\n",
    "    print(\"Fastball accuracy:\",ff_acc)\n",
    "    print(\"______________________________________\")\n",
    "    print(\"Accuracy:\",accuracy)\n",
    "    print(\"Accuracy above naive guess:\",accuracy - ff_rate)\n",
    "    print(\"______________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this for different pitcher\n",
    "'''tag_to_ix = {'CU':0,\n",
    "             'FF':1,\n",
    "             'SL':2,\n",
    "             'CH':3}'''\n",
    "tag_to_ix = {'NF':0,\n",
    "             'FF':1}\n",
    "\n",
    "# -- Input Dimensions -- DO NOT CHANGE\n",
    "PREV_PITCH_DIM = 25\n",
    "NUM_PREV_PITCHES = 3\n",
    "GAME_STATE_DIM = 15 \n",
    "GAME_OUT_DIM = 15\n",
    "\n",
    "# -- Hyperparameters -- DO CHANGE \n",
    "HIDDEN_DIM = 120\n",
    "OUT_DIM = 15\n",
    "lstm_layers = 1\n",
    "learning_rate = 0.0001\n",
    "\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "    \n",
    "class PitchPredict(nn.Module):\n",
    "    def __init__(self, prev_pitch_dim, hidden_dim, num_prev_pitches,out_dim, game_state_dim, game_out_dim, num_ptypes):\n",
    "        super(PitchPredict, self).__init__()\n",
    "        #get constants\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.prev_pitch_dim = prev_pitch_dim\n",
    "        self.num_prev_pitches = num_prev_pitches\n",
    "        self.out_dim = out_dim\n",
    "        self.game_state_dim = game_state_dim\n",
    "        self.game_out_dim = game_out_dim\n",
    "        \n",
    "        ####Define Layers####\n",
    "        \n",
    "        ########################## LSTM for past five pitches#######################################\n",
    "        # The LSTM takes previous pitch vectors as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.RNN(prev_pitch_dim, hidden_dim,num_layers=lstm_layers,batch_first=True)#FIDDLE WITH num_layers\n",
    "\n",
    "        # The linear layer that maps from hidden state space to a vector\n",
    "        # with dimensionality OUT_DIM\n",
    "        self.hidden2out = nn.Linear(hidden_dim, out_dim)\n",
    "        \n",
    "        ############## FULLY CONNECTED LAYERS for LSTM OUTPUT + game_state vector #################\n",
    "        \n",
    "        # This Fully connected layer maps from the output of the final hidden layer output from the LSTM,\n",
    "        # dimension = OUT_DIM, with the game state vector, dimension = GAME_STATE_DIM\n",
    "        # to a vector of length of the number of ptypes to pass through softmax for probabilities\n",
    "        self.fc1 = nn.Linear((self.out_dim + self.game_out_dim), 2)\n",
    "\n",
    "                             \n",
    "    def forward(self, rep):\n",
    "        past_pitches,game_state = rep\n",
    "        lstm_out, _ = self.lstm(past_pitches.view(batch_size,self.num_prev_pitches, -1))\n",
    "        learned_rep = self.hidden2out(lstm_out.view(batch_size,self.num_prev_pitches, -1))\n",
    "        game_rep = game_state.view(batch_size,self.game_state_dim)\n",
    "        #game_rep = self.l1(game_state.view(batch_size,self.game_state_dim))\n",
    "        #game_rep = F.relu(game_rep)\n",
    "        encoding = learned_rep[:,self.num_prev_pitches - 1:,:]\n",
    "        fc_in = torch.cat((encoding.view(batch_size,self.out_dim),game_rep.view(batch_size,self.game_out_dim)),dim=1)\n",
    "        fc = self.fc1(fc_in.view(batch_size,self.game_out_dim+self.out_dim))\n",
    "        tag_scores = F.log_softmax(fc,dim=0)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Pre-Training Accuracy*****************\n",
      "______________________________________\n",
      "Non-Fastball rate: 0.42080338266384776\n",
      "Predicted Non-Fastball rate: 0.49192389006342496\n",
      "Non-Fastball accuracy: 0.5162781350482315\n",
      "______________________________________\n",
      "Fastball rate: 0.5791966173361522\n",
      "Predicted Fastball rate: 0.508076109936575\n",
      "Fastball accuracy: 0.5257701854285297\n",
      "______________________________________\n",
      "Accuracy: 0.5217758985200845\n",
      "Accuracy above naive guess: -0.057420718816067695\n",
      "______________________________________\n",
      "**************************Training*****************************\n",
      "epoch: 1 loss: 3.8729336261749268\n",
      "epoch: 2 loss: 3.871647596359253\n",
      "epoch: 3 loss: 3.872035026550293\n",
      "epoch: 4 loss: 3.872884511947632\n",
      "epoch: 5 loss: 3.8739614486694336\n",
      "epoch: 6 loss: 3.875012159347534\n",
      "epoch: 7 loss: 3.8759572505950928\n",
      "epoch: 8 loss: 3.8768155574798584\n",
      "epoch: 9 loss: 3.8775980472564697\n",
      "epoch: 10 loss: 3.8782894611358643\n",
      "epoch: 11 loss: 3.8788743019104004\n",
      "epoch: 12 loss: 3.879343271255493\n",
      "epoch: 13 loss: 3.8796796798706055\n",
      "epoch: 14 loss: 3.879878520965576\n",
      "epoch: 15 loss: 3.8800859451293945\n",
      "epoch: 16 loss: 3.8802950382232666\n",
      "epoch: 17 loss: 3.8804755210876465\n",
      "epoch: 18 loss: 3.880620002746582\n",
      "epoch: 19 loss: 3.8807289600372314\n",
      "epoch: 20 loss: 3.880805253982544\n",
      "epoch: 21 loss: 3.8808515071868896\n",
      "epoch: 22 loss: 3.8808722496032715\n",
      "epoch: 23 loss: 3.880871295928955\n",
      "epoch: 24 loss: 3.8808529376983643\n",
      "epoch: 25 loss: 3.8808176517486572\n",
      "epoch: 26 loss: 3.8807718753814697\n",
      "epoch: 27 loss: 3.880715847015381\n",
      "epoch: 28 loss: 3.880652666091919\n",
      "epoch: 29 loss: 3.880582332611084\n",
      "epoch: 30 loss: 3.880507230758667\n",
      "epoch: 31 loss: 3.8804290294647217\n",
      "epoch: 32 loss: 3.880350351333618\n",
      "epoch: 33 loss: 3.880270004272461\n",
      "epoch: 34 loss: 3.880190134048462\n",
      "epoch: 35 loss: 3.8801095485687256\n",
      "epoch: 36 loss: 3.8800246715545654\n",
      "epoch: 37 loss: 3.8799328804016113\n",
      "epoch: 38 loss: 3.8798305988311768\n",
      "epoch: 39 loss: 3.8797202110290527\n",
      "epoch: 40 loss: 3.8796067237854004\n",
      "epoch: 41 loss: 3.8794848918914795\n",
      "epoch: 42 loss: 3.87935733795166\n",
      "epoch: 43 loss: 3.879223108291626\n",
      "epoch: 44 loss: 3.879082679748535\n",
      "epoch: 45 loss: 3.8789381980895996\n",
      "epoch: 46 loss: 3.8787906169891357\n",
      "epoch: 47 loss: 3.8786420822143555\n",
      "epoch: 48 loss: 3.8784899711608887\n",
      "epoch: 49 loss: 3.87833833694458\n",
      "epoch: 50 loss: 3.8781845569610596\n",
      "epoch: 51 loss: 3.8780274391174316\n",
      "epoch: 52 loss: 3.877868890762329\n",
      "epoch: 53 loss: 3.8777072429656982\n",
      "epoch: 54 loss: 3.8775434494018555\n",
      "epoch: 55 loss: 3.8773751258850098\n",
      "epoch: 56 loss: 3.8772048950195312\n",
      "epoch: 57 loss: 3.8770318031311035\n",
      "epoch: 58 loss: 3.8768553733825684\n",
      "epoch: 59 loss: 3.8766748905181885\n",
      "epoch: 60 loss: 3.876492500305176\n",
      "epoch: 61 loss: 3.8763070106506348\n",
      "epoch: 62 loss: 3.8761181831359863\n",
      "epoch: 63 loss: 3.875927209854126\n",
      "epoch: 64 loss: 3.875734806060791\n",
      "epoch: 65 loss: 3.8755393028259277\n",
      "epoch: 66 loss: 3.8753411769866943\n",
      "epoch: 67 loss: 3.875140428543091\n",
      "epoch: 68 loss: 3.8749375343322754\n",
      "epoch: 69 loss: 3.8747315406799316\n",
      "epoch: 70 loss: 3.874523401260376\n",
      "epoch: 71 loss: 3.874311923980713\n",
      "epoch: 72 loss: 3.8740973472595215\n",
      "epoch: 73 loss: 3.8738796710968018\n",
      "epoch: 74 loss: 3.873659133911133\n",
      "epoch: 75 loss: 3.873434066772461\n",
      "epoch: 76 loss: 3.8732070922851562\n",
      "epoch: 77 loss: 3.872976064682007\n",
      "epoch: 78 loss: 3.8727428913116455\n",
      "epoch: 79 loss: 3.8725063800811768\n",
      "epoch: 80 loss: 3.872267484664917\n",
      "epoch: 81 loss: 3.87202525138855\n",
      "epoch: 82 loss: 3.87178111076355\n",
      "epoch: 83 loss: 3.8715343475341797\n",
      "epoch: 84 loss: 3.8712854385375977\n",
      "epoch: 85 loss: 3.871034622192383\n",
      "epoch: 86 loss: 3.8707828521728516\n",
      "epoch: 87 loss: 3.8705294132232666\n",
      "epoch: 88 loss: 3.8702750205993652\n",
      "epoch: 89 loss: 3.8700203895568848\n",
      "epoch: 90 loss: 3.869764804840088\n",
      "epoch: 91 loss: 3.8695080280303955\n",
      "epoch: 92 loss: 3.8692526817321777\n",
      "epoch: 93 loss: 3.8689966201782227\n",
      "epoch: 94 loss: 3.868739604949951\n",
      "epoch: 95 loss: 3.8684844970703125\n",
      "epoch: 96 loss: 3.8682284355163574\n",
      "epoch: 97 loss: 3.8679726123809814\n",
      "epoch: 98 loss: 3.867720127105713\n",
      "epoch: 99 loss: 3.8674657344818115\n",
      "epoch: 100 loss: 3.8672122955322266\n",
      "epoch: 101 loss: 3.8669605255126953\n",
      "epoch: 102 loss: 3.866708755493164\n",
      "epoch: 103 loss: 3.8664584159851074\n",
      "epoch: 104 loss: 3.866208553314209\n",
      "epoch: 105 loss: 3.8659605979919434\n",
      "epoch: 106 loss: 3.8657138347625732\n",
      "epoch: 107 loss: 3.865466833114624\n",
      "epoch: 108 loss: 3.865222454071045\n",
      "epoch: 109 loss: 3.864978551864624\n",
      "epoch: 110 loss: 3.864736318588257\n",
      "epoch: 111 loss: 3.864495277404785\n",
      "epoch: 112 loss: 3.864255905151367\n",
      "epoch: 113 loss: 3.8640172481536865\n",
      "epoch: 114 loss: 3.8637828826904297\n",
      "epoch: 115 loss: 3.8635475635528564\n",
      "epoch: 116 loss: 3.8633153438568115\n",
      "epoch: 117 loss: 3.8630852699279785\n",
      "epoch: 118 loss: 3.862856864929199\n",
      "epoch: 119 loss: 3.862628221511841\n",
      "epoch: 120 loss: 3.862401008605957\n",
      "epoch: 121 loss: 3.8621761798858643\n",
      "epoch: 122 loss: 3.8619496822357178\n",
      "epoch: 123 loss: 3.861722946166992\n",
      "epoch: 124 loss: 3.861495018005371\n",
      "epoch: 125 loss: 3.861264944076538\n",
      "epoch: 126 loss: 3.8610336780548096\n",
      "epoch: 127 loss: 3.8607969284057617\n",
      "epoch: 128 loss: 3.860556125640869\n",
      "epoch: 129 loss: 3.8603103160858154\n",
      "epoch: 130 loss: 3.8600597381591797\n",
      "epoch: 131 loss: 3.859802484512329\n",
      "epoch: 132 loss: 3.8595407009124756\n",
      "epoch: 133 loss: 3.8592722415924072\n",
      "epoch: 134 loss: 3.8590002059936523\n",
      "epoch: 135 loss: 3.8587253093719482\n",
      "epoch: 136 loss: 3.8584489822387695\n",
      "epoch: 137 loss: 3.858175754547119\n",
      "epoch: 138 loss: 3.857903242111206\n",
      "epoch: 139 loss: 3.857637882232666\n",
      "epoch: 140 loss: 3.857379198074341\n",
      "epoch: 141 loss: 3.8571274280548096\n",
      "epoch: 142 loss: 3.8568854331970215\n",
      "epoch: 143 loss: 3.8566489219665527\n",
      "epoch: 144 loss: 3.856419086456299\n",
      "epoch: 145 loss: 3.856198787689209\n",
      "epoch: 146 loss: 3.8559818267822266\n",
      "epoch: 147 loss: 3.855771541595459\n",
      "epoch: 148 loss: 3.8555667400360107\n",
      "epoch: 149 loss: 3.855365514755249\n",
      "epoch: 150 loss: 3.8551700115203857\n",
      "epoch: 151 loss: 3.854978322982788\n",
      "epoch: 152 loss: 3.8547885417938232\n",
      "epoch: 153 loss: 3.8546030521392822\n",
      "epoch: 154 loss: 3.8544182777404785\n",
      "epoch: 155 loss: 3.8542346954345703\n",
      "epoch: 156 loss: 3.8540542125701904\n",
      "epoch: 157 loss: 3.8538730144500732\n",
      "epoch: 158 loss: 3.853692054748535\n",
      "epoch: 159 loss: 3.8535115718841553\n",
      "epoch: 160 loss: 3.853332281112671\n",
      "epoch: 161 loss: 3.853151559829712\n",
      "epoch: 162 loss: 3.852968215942383\n",
      "epoch: 163 loss: 3.852786064147949\n",
      "epoch: 164 loss: 3.852602005004883\n",
      "epoch: 165 loss: 3.8524155616760254\n",
      "epoch: 166 loss: 3.8522281646728516\n",
      "epoch: 167 loss: 3.852038621902466\n",
      "epoch: 168 loss: 3.851846218109131\n",
      "epoch: 169 loss: 3.851652145385742\n",
      "epoch: 170 loss: 3.851457118988037\n",
      "epoch: 171 loss: 3.8512587547302246\n",
      "epoch: 172 loss: 3.851057529449463\n",
      "epoch: 173 loss: 3.8508548736572266\n",
      "epoch: 174 loss: 3.8506479263305664\n",
      "epoch: 175 loss: 3.850440740585327\n",
      "epoch: 176 loss: 3.8502302169799805\n",
      "epoch: 177 loss: 3.8500168323516846\n",
      "epoch: 178 loss: 3.8498013019561768\n",
      "epoch: 179 loss: 3.8495843410491943\n",
      "epoch: 180 loss: 3.8493642807006836\n",
      "epoch: 181 loss: 3.8491415977478027\n",
      "epoch: 182 loss: 3.8489181995391846\n",
      "epoch: 183 loss: 3.848691940307617\n",
      "epoch: 184 loss: 3.848466157913208\n",
      "epoch: 185 loss: 3.8482370376586914\n",
      "epoch: 186 loss: 3.8480072021484375\n",
      "epoch: 187 loss: 3.8477768898010254\n",
      "epoch: 188 loss: 3.847545862197876\n",
      "epoch: 189 loss: 3.8473148345947266\n",
      "epoch: 190 loss: 3.847083806991577\n",
      "epoch: 191 loss: 3.8468520641326904\n",
      "epoch: 192 loss: 3.8466200828552246\n",
      "epoch: 193 loss: 3.846388816833496\n",
      "epoch: 194 loss: 3.8461577892303467\n",
      "epoch: 195 loss: 3.8459277153015137\n",
      "epoch: 196 loss: 3.8456978797912598\n",
      "epoch: 197 loss: 3.8454689979553223\n",
      "epoch: 198 loss: 3.8452401161193848\n",
      "epoch: 199 loss: 3.845010995864868\n",
      "epoch: 200 loss: 3.844782829284668\n",
      "****************Post-Training Accuracy********************\n",
      "______________________________________\n",
      "Non-Fastball rate: 0.42080338266384776\n",
      "Predicted Non-Fastball rate: 0.49264270613107825\n",
      "Non-Fastball accuracy: 0.6520297427652733\n",
      "______________________________________\n",
      "Fastball rate: 0.5791966173361522\n",
      "Predicted Fastball rate: 0.5073572938689218\n",
      "Fastball accuracy: 0.6231566652065995\n",
      "______________________________________\n",
      "Accuracy: 0.635306553911205\n",
      "Accuracy above naive guess: 0.05610993657505281\n",
      "______________________________________\n",
      "**********************************************************\n"
     ]
    }
   ],
   "source": [
    "model = PitchPredict(PREV_PITCH_DIM, HIDDEN_DIM, NUM_PREV_PITCHES, OUT_DIM, GAME_STATE_DIM, GAME_OUT_DIM, len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    print(\"***************Pre-Training Accuracy*****************\")\n",
    "    test_accuracy(train_batches,model)\n",
    "print(\"**************************Training*****************************\")\n",
    "for epoch in range(200):\n",
    "    #shuffle(train_batches)\n",
    "    for batch in train_batches:\n",
    "        prev_pitches,pre_pitch, ptypes = batch\n",
    "        \n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        #get input tensors ready\n",
    "        prevs_in = torch.tensor(prev_pitches, dtype=torch.float)\n",
    "        game_state_in = torch.tensor(pre_pitch, dtype=torch.float)\n",
    "        \n",
    "        #get target value\n",
    "        #target = tag_to_ix[ptype]\n",
    "        target = [ tag_to_ix[ptype] for ptype in ptypes]\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model((prevs_in,game_state_in))\n",
    "               \n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, torch.tensor(target,dtype=torch.long))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        preds = [tag_score.max(0) for tag_score in tag_scores]\n",
    "\n",
    "                \n",
    "    #display post-epoch results\n",
    "    print('epoch:',epoch+1,\"loss:\",loss.item())\n",
    "\n",
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    print(\"****************Post-Training Accuracy********************\")\n",
    "    test_accuracy(train_batches,model.eval())\n",
    "    print(\"**********************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************Validation Accuracy********************\n",
      "______________________________________\n",
      "Non-Fastball rate: 0.41668789808917195\n",
      "Predicted Non-Fastball rate: 0.4965605095541401\n",
      "Non-Fastball accuracy: 0.6398654845612962\n",
      "______________________________________\n",
      "Fastball rate: 0.583312101910828\n",
      "Predicted Fastball rate: 0.5034394904458599\n",
      "Fastball accuracy: 0.6058091286307054\n",
      "______________________________________\n",
      "Accuracy: 0.62\n",
      "Accuracy above naive guess: 0.036687898089171944\n",
      "______________________________________\n",
      "**********************************************************\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"****************Validation Accuracy********************\")\n",
    "    test_accuracy(validate_batches,model)\n",
    "    print(\"**********************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************Test Accuracy********************\n",
      "______________________________________\n",
      "Non-Fastball rate: 0.4173248407643312\n",
      "Predicted Non-Fastball rate: 0.4937579617834395\n",
      "Non-Fastball accuracy: 0.6416361416361417\n",
      "______________________________________\n",
      "Fastball rate: 0.5826751592356688\n",
      "Predicted Fastball rate: 0.5062420382165606\n",
      "Fastball accuracy: 0.6121556624398776\n",
      "______________________________________\n",
      "Accuracy: 0.6244585987261146\n",
      "Accuracy above naive guess: 0.04178343949044583\n",
      "______________________________________\n",
      "**********************************************************\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"****************Test Accuracy********************\")\n",
    "    test_accuracy(test_batches,model)\n",
    "    print(\"**********************************************************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
